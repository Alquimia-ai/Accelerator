{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746d98ff-75fc-4177-a596-46ddb8ecc558",
   "metadata": {},
   "source": [
    "# Fine tune distilbert to perform Text classification \n",
    "\n",
    "This notebook is intended to train `text-classification` models based on `distilbert base uncased` model. To do so we are using [Transformers ü§óü§ó](https://huggingface.co/docs/transformers/index).\n",
    "\n",
    "### Considerations\n",
    "- The dataset must have column \"text\" where all the input questions are setted\n",
    "- An `S3 Instance` is required to correctly store the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e83f33-ca47-4c79-9e89-c97842753f1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Install required libs   üì•üì•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c12f0a-4b1a-4402-8b4a-75f873a2e14b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate  mlflow tf-keras seaborn optimum[openvino,nncf,exporters] psutil pynvml -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85299f-54f3-47ea-aa5f-0478ccf2c98a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset manipulation & env preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d253b44-7030-4b42-af67-b78027c88dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = Path().resolve()\n",
    "sys.path.append(str(notebook_dir.parents[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fc1f6-d9ac-4a85-b2ff-0a8c76c0dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115af02-4ac8-4013-ab0e-0fbe1ad2d9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "input_column_name=\"text\"\n",
    "labeled_dataset = \"datasets/dataset.csv\"\n",
    "df = pd.read_csv(labeled_dataset)\n",
    "file_label2id = open('datasets/label2id.json')\n",
    "file_id2label = open('datasets/id2label.json')\n",
    "label2id = json.load(file_label2id)\n",
    "id2label=json.load(file_id2label)\n",
    "df.head()\n",
    "df['label'] = df[output_column_name].replace(label2id)\n",
    "df.head(3)\n",
    "print(f\"The label2id json loaded correctly: {label2id}\")\n",
    "print(f\"The id2label json loaded correctly: {id2label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f21ef-f87c-4f02-8442-889b7802144e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Give a name to your model and version  üßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÇÔ∏è\n",
    "\n",
    "This process is crucial mainly because a `text-classification` model can be intended for a huge amount of approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1030d-b6be-4f52-84b0-5fa47d7fa403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"intents-copa\"\n",
    "MLFLOW_EXPERIMENT = \"showcases\"\n",
    "base_model = 'distilbert-base-uncased'\n",
    "MLFLOW_RUN_NAME = \"V1 Intents for copa model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18e64d-f5c5-4b38-8777-964cfa5223fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(dataset=df,label2id,id2label,base_model,model_name,MLFLOW_EXPERIMENT,MLFLOW_RUN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8554c-e0de-4f83-9802-c5c0f35e41fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Fine tune model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fef042c-4743-4404-922d-480b041c8da8",
   "metadata": {},
   "source": [
    "### Batch size per epoch\n",
    "\n",
    "So if you have a batch size of 20 then \n",
    "\n",
    "total_dataset/batch_size = n\n",
    "\n",
    "n represents the total amount of batches per epoch\n",
    "\n",
    "### How many times does my model going to be trained?\n",
    "\n",
    "n*epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1dc20-5fcd-4f8d-9cc7-e39184bda1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Save pytorch \n",
    "trainer.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153b8b0-d9aa-47a7-9cc3-cd0a49bcf655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment_by_name(experiment)\n",
    "filter_string = f\"tags.mlflow.runName = '{run_name}'\"\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=filter_string\n",
    ")\n",
    "\n",
    "# Extract the run_id from the DataFrame\n",
    "if not runs.empty:\n",
    "    previous_run_id = runs.iloc[0]['run_id']\n",
    "    print(f\"Run ID: {previous_run_id}\")\n",
    "else:\n",
    "    print(\"No run found with the specified name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34eacb0-078b-42cb-a60b-299244f43657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow.data\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from pathlib import Path\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7cfee9-2f8e-48ec-956e-d7caa5491189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def uploadModel(run_id:str):\n",
    "    train_dataset: PandasDataset = mlflow.data.from_pandas(df_train, source=\"Label Studio\")\n",
    "    test_dataset: PandasDataset = mlflow.data.from_pandas(df_test, source=\"Label Studio\")\n",
    "    with mlflow.start_run(run_id=previous_run_id) as run:\n",
    "        ORTModelForSequenceClassification.from_pretrained(model_name,export=True).save_pretrained(f\"{model_name}_onnx\")\n",
    "        tmp_dir = Path(f\"{model_name}_onnx\")\n",
    "        mlflow.log_artifacts(tmp_dir, artifact_path=model_name)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\",artifact_path=model_name)\n",
    "        tokenizer.save_pretrained(f\"{model_name}_onnx\")\n",
    "        onnx_model = onnx.load_model(f\"{model_name}_onnx/model.onnx\")\n",
    "        model_info = mlflow.onnx.log_model(onnx_model,model_name,registered_model_name=model_name)\n",
    "        mlflow.log_input(train_dataset, context=\"training\")\n",
    "        mlflow.log_input(test_dataset,context=\"validation\")\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b56400-4a0a-42b0-be35-5fd05dbd6743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uploadModel(previous_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086070fc-b4ab-4d5f-909e-729114d943ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c5e2c-cd92-4df0-8e82-a1587f5ba835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Delete directories in Jupyter Notebook\n",
    "import shutil\n",
    "\n",
    "# Remove the local model directory\n",
    "shutil.rmtree(model_name)\n",
    "shutil.rmtree(run_name)\n",
    "os.remove(labeled_dataset)\n",
    "shutil.rmtree(f\"{model_name}_onnx\")\n",
    "os.remove(\"datasets/label2id.json\")\n",
    "os.remove(\"datasets/id2label.json\")\n",
    "os.remove(\"./confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f2a2b2-6e8e-47ce-bbe0-83d82a88548e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
