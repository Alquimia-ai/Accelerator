{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e48e885-eacb-4d44-b6b6-3d61ca42cb48",
   "metadata": {},
   "source": [
    "# **E.T.L.**\n",
    "\n",
    "This notebook demonstrates how to use two ETL frameworks, **PyMuPDF** and **Docling**, to efficiently convert PDF documents into Markdown files. \n",
    "\n",
    "It supports processing multiple PDFs, saving the output as structured Markdown files for use in downstream tasks such as document indexing, text analysis and feeding RAG applications.\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9534b8-df85-40c8-a378-da96205ade5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf pymupdf4llm docling -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659b35e5-679b-4add-b1d5-b6fff80fe008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, enter the following information...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\t- Project name: papers\n",
      "\t - Topic name: LLMs\n"
     ]
    }
   ],
   "source": [
    "print(\"Please, enter the following information...\")\n",
    "\n",
    "project = input(\"\\t- Project name:\")\n",
    "topic = input(\"\\t - Topic name:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d11d0-054f-49a1-91ca-253f9dc321f2",
   "metadata": {},
   "source": [
    "## [PyMuPDF](https://pymupdf.readthedocs.io/en/latest/pymupdf4llm/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0724cb8-1eb5-4ee7-bf35-11e434d6271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import pymupdf4llm\n",
    "from pymupdf4llm import to_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08704ea7-080d-490e-b9f6-9d6b2134020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a PDF to Markdown\n",
    "\n",
    "def pymupdf_pdf_to_md(input_pdf_path, output_md_path):\n",
    "    try:\n",
    "        doc = pymupdf.open(input_pdf_path)  # Open the PDF\n",
    "        page_list = list(range(0, len(doc)))  # Define desired pages\n",
    "        md_text = to_markdown(doc, pages=page_list)  # Convert to Markdown\n",
    "\n",
    "        # Write the Markdown string to a file\n",
    "        with open(output_md_path, \"w\") as output:\n",
    "            output.write(md_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_pdf_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901c9907-5017-41c8-9382-0bc76055e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mProcessing Scaling Laws for Neural Language Models.pdf...\u001b[0m\n",
      "Processing projects/papers/pdfs/LLMs/Scaling Laws for Neural Language Models.pdf...\n",
      "[                                        ] (0/3[=                                       ] ( 1/3[==                                      ] ( 2/30[====                                    ] ( 3/30=[=====                                   ] ( 4/3[======                                  ] ( 5/30[========                                ] ( 6/30=[=========                               ] ( 7/3[==========                              ] ( 8/30[============                            ] ( 9/30=[=============                           ] (10/3[==============                          ] (11/30[================                        ] (12/30=[=================                       ] (13/3[==================                      ] (14/30[====================                    ] (15/30=[=====================                   ] (16/3[======================                  ] (17/30[========================                ] (18/30=[=========================               ] (19/3[==========================              ] (20/30[============================            ] (21/30=[=============================           ] (22/3[==============================          ] (23/30[================================        ] (24/30=[=================================       ] (25/3[==================================      ] (26/30[====================================    ] (27/30=[=====================================   ] (28/3[======================================  ] (29/30[========================================] (30/30]\n",
      "\u001b[1mProcessing Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.pdf...\u001b[0m\n",
      "Processing projects/papers/pdfs/LLMs/Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.pdf...\n",
      "[                                        ] (0/67[                                        ] ( 1/67[=                                       ] ( 2/[=                                       ] ( 3/6[==                                      ] ( 4/6[==                                      ] ( 5/67[===                                     ] ( 6/6[====                                    ] ( 7/6[====                                    ] ( 8/67[=====                                   ] ( 9/[=====                                   ] (10/6[======                                  ] (11/67[=======                                 ] (12/[=======                                 ] (13/6[========                                ] (14/6[========                                ] (15/67[=========                               ] (16/6[==========                              ] (17/6[==========                              ] (18/67[===========                             ] (19/[===========                             ] (20/6[============                            ] (21/67[=============                           ] (22/67[=============                           ] (23/6[==============                          ] (24/6[==============                          ] (25/67[===============                         ] (26/6[================                        ] (27/6[================                        ] (28/67[=================                       ] (29/[=================                       ] (30/6[==================                      ] (31/67[===================                     ] (32/[===================                     ] (33/6[====================                    ] (34/6[====================                    ] (35/67[=====================                   ] (36/6[======================                  ] (37/6[======================                  ] (38/67[=======================                 ] (39/[=======================                 ] (40/6[========================                ] (41/67[=========================               ] (42/[=========================               ] (43/6[==========================              ] (44/6[==========================              ] (45/67[===========================             ] (46/6[============================            ] (47/6[============================            ] (48/67[=============================           ] (49/[=============================           ] (50/6[==============================          ] (51/67[===============================         ] (52/[===============================         ] (53/6[================================        ] (54/6[================================        ] (55/67[=================================       ] (56/6[==================================      ] (57/6[==================================      ] (58/67[===================================     ] (59/67[===================================     ] (60/6[====================================    ] (61/67[=====================================   ] (62/67[=====================================   ] (63/6[======================================  ] (64/6[======================================  ] (65/67[======================================= ] (66/[========================================] (67/67]\n",
      "\u001b[1mProcessing BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf...\u001b[0m\n",
      "Processing projects/papers/pdfs/LLMs/BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/16==[=====                                   ] ( 2/1=[=======                                 ] ( 3/1==[==========                              ] ( 4/16=[============                            ] ( 5/16==[===============                         ] ( 6/1=[=================                       ] ( 7/1==[====================                    ] ( 8/16=[======================                  ] ( 9/16==[=========================               ] (10/1=[===========================             ] (11/1==[==============================          ] (12/16=[================================        ] (13/16==[===================================     ] (14/1=[=====================================   ] (15/1==[========================================] (16/16]\n",
      "\u001b[1mProcessing ZeRO: Memory Optimizations Toward Training Trillion Parameter Models.pdf...\u001b[0m\n",
      "Processing projects/papers/pdfs/LLMs/ZeRO: Memory Optimizations Toward Training Trillion Parameter Models.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2=[=====                                   ] ( 3/2[======                                  ] ( 4/24=[========                                ] ( 5/24=[==========                              ] ( 6/24[===========                             ] ( 7/2=[=============                           ] ( 8/2=[===============                         ] ( 9/2[================                        ] (10/24=[==================                      ] (11/24=[====================                    ] (12/24[=====================                   ] (13/2=[=======================                 ] (14/2=[=========================               ] (15/2[==========================              ] (16/24=[============================            ] (17/24=[==============================          ] (18/24[===============================         ] (19/2=[=================================       ] (20/2=[===================================     ] (21/2[====================================    ] (22/24=[======================================  ] (23/24=[========================================] (24/24]\n",
      "\u001b[1mProcessing Improving Language Understanding by Generative Pre-Training.pdf...\u001b[0m\n",
      "Processing projects/papers/pdfs/LLMs/Improving Language Understanding by Generative Pre-Training.pdf...\n",
      "[                                        ] (0/1==[===                                     ] ( 1/1==[======                                  ] ( 2/12===[==========                              ] ( 3/12==[=============                           ] ( 4/1==[================                        ] ( 5/12===[====================                    ] ( 6/12==[=======================                 ] ( 7/1==[==========================              ] ( 8/12===[==============================          ] ( 9/12==[=================================       ] (10/1==[====================================    ] (11/12===[========================================] (12/12]\n",
      "\u001b[1mProcessing Attention is all you need.pdf...\u001b[0m\n",
      "Processing projects/papers/pdfs/LLMs/Attention is all you need.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/15==[=====                                   ] ( 2/1=[========                                ] ( 3/15==[==========                              ] ( 4/15==[=============                           ] ( 5/1=[================                        ] ( 6/15==[==================                      ] ( 7/15==[=====================                   ] ( 8/1=[========================                ] ( 9/15==[==========================              ] (10/15==[=============================           ] (11/1=[================================        ] (12/15==[==================================      ] (13/15==[=====================================   ] (14/1=[========================================] (15/15]\n",
      "\u001b[1mProcessing Language Models are Few-Shot Learners.pdf...\u001b[0m\n",
      "Processing projects/papers/pdfs/LLMs/Language Models are Few-Shot Learners.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2[====                                    ] ( 3/25=[======                                  ] ( 4/25=[========                                ] ( 5/25[=========                               ] ( 6/2=[===========                             ] ( 7/2[============                            ] ( 8/25=[==============                          ] ( 9/25=[================                        ] (10/25[=================                       ] (11/2=[===================                     ] (12/2[====================                    ] (13/25=[======================                  ] (14/25=[========================                ] (15/25[=========================               ] (16/2=[===========================             ] (17/2[============================            ] (18/25=[==============================          ] (19/25=[================================        ] (20/25[=================================       ] (21/2=[===================================     ] (22/2[====================================    ] (23/25=[======================================  ] (24/25=[========================================] (25/25]\n",
      "\u001b[1mProcessing Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism.pdf...\u001b[0m\n",
      "Processing projects/papers/pdfs/LLMs/Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/15==[=====                                   ] ( 2/1=[========                                ] ( 3/15==[==========                              ] ( 4/15==[=============                           ] ( 5/1=[================                        ] ( 6/15==[==================                      ] ( 7/15==[=====================                   ] ( 8/1=[========================                ] ( 9/15==[==========================              ] (10/15==[=============================           ] (11/1=[================================        ] (12/15==[==================================      ] (13/15==[=====================================   ] (14/1=[========================================] (15/15]\n",
      "----- \u001b[1mConversion completed!\u001b[0m -----\n"
     ]
    }
   ],
   "source": [
    "# Input and output directories\n",
    "input_dir = f\"projects/{project}/pdfs/{topic}\"\n",
    "output_dir = f\"projects/{project}/mds_pymupdf/{topic}\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each PDF file in the input directory\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith(\".pdf\"):  # Ensure it's a PDF file\n",
    "        input_pdf_path = os.path.join(input_dir, file_name)\n",
    "        output_md_path = os.path.join(output_dir, file_name.rsplit(\".\", 1)[0] + \".md\")\n",
    "\n",
    "        print(f\"\\033[1mProcessing {file_name}...\\033[0m\")\n",
    "        pymupdf_pdf_to_md(input_pdf_path, output_md_path)\n",
    "\n",
    "print(\"----- \\033[1mConversion completed!\\033[0m -----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e70a4-dad7-47d0-a09c-b247e3565973",
   "metadata": {},
   "source": [
    "## [Docling](https://github.com/DS4SD/docling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ae7ce0-f568-447d-b540-2b0fecc47d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5eea48-fab6-41cd-a9d4-cc740d35c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a PDF to Markdown\n",
    "\n",
    "def docling_pdf_to_md(input_pdf_path, output_md_path):\n",
    "    source = input_pdf_path\n",
    "    converter = DocumentConverter() # Initialize converter\n",
    "    try:\n",
    "        # Convert to MD\n",
    "        result = converter.convert(source) \n",
    "        md_text = result.document.export_to_markdown()\n",
    "\n",
    "        # Write the Markdown string to a file\n",
    "        with open(output_md_path, \"w\") as output:\n",
    "            output.write(md_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_pdf_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd7fafd-ced3-4ed3-8708-18a96e57f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mProcessing Scaling Laws for Neural Language Models.pdf...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mProcessing Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.pdf...\u001b[0m\n",
      "\u001b[1mProcessing BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mProcessing ZeRO: Memory Optimizations Toward Training Trillion Parameter Models.pdf...\u001b[0m\n",
      "\u001b[1mProcessing Improving Language Understanding by Generative Pre-Training.pdf...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mProcessing Attention is all you need.pdf...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mProcessing Language Models are Few-Shot Learners.pdf...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mProcessing Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism.pdf...\u001b[0m\n",
      "----- \u001b[1mConversion completed!\u001b[0m -----\n"
     ]
    }
   ],
   "source": [
    "# Input and output directories\n",
    "input_dir = f\"projects/{project}/pdfs/{topic}\"\n",
    "output_dir = f\"projects/{project}/mds_docling/{topic}\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each PDF file in the input directory\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith(\".pdf\"):  # Ensure it's a PDF file\n",
    "        input_pdf_path = os.path.join(input_dir, file_name)\n",
    "        output_md_path = os.path.join(output_dir, file_name.rsplit(\".\", 1)[0] + \".md\")\n",
    "\n",
    "        print(f\"\\033[1mProcessing {file_name}...\\033[0m\")\n",
    "        docling_pdf_to_md(input_pdf_path, output_md_path)\n",
    "\n",
    "print(\"----- \\033[1mConversion completed!\\033[0m -----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34b6c6-0147-423a-b49e-aa11a2f9ad11",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
